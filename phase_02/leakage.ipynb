{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.  Imports & Logging\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from rapidfuzz import fuzz\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)-8s %(name)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger(\"sentence_cleaner\")\n",
    "\n",
    "# %% \n",
    "# 1.  Configuration\n",
    "CSV_IN       = Path(\"/Users/matthijstentije/University/MSc_Data-Science/Thesis/MSc_Data_Science_Thesis/Notebooks/Phase_02/aggregated_sentences.csv\")\n",
    "CSV_OUT      = Path(\"output/sentences_cleaned.csv\")\n",
    "ENCODING     = \"utf-8\"\n",
    "FUZZY_THRESH = 70\n",
    "\n",
    "# %% \n",
    "# 2.  Preflight & Load\n",
    "if not CSV_IN.exists():\n",
    "    logger.error(f\"Input file not found: {CSV_IN}\")\n",
    "    raise FileNotFoundError(f\"{CSV_IN} does not exist\")\n",
    "logger.info(f\"Reading input CSV from {CSV_IN}\")\n",
    "df = pd.read_csv(CSV_IN, encoding=ENCODING, on_bad_lines=\"warn\")\n",
    "logger.info(f\"Loaded {len(df)} rows\")\n",
    "\n",
    "# %% df['sentence'] = df['sentence'].fillna('').astype(str).str.strip()\n",
    "\n",
    "\n",
    "mask_dots   = df['sentence'].str.match(r'^\\.+\\s*$', na=False)\n",
    "mask_colons = df['sentence'].str.match(r'^:+\\s*$', na=False)\n",
    "mask_empty  = df['sentence'].eq('')\n",
    "mask_removed =  mask_dots | mask_colons | mask_empty \n",
    "\n",
    "removed_df = df[mask_removed]\n",
    "logger.info(f\"Found {len(removed_df)} sentences to remove:\")\n",
    "display(removed_df[['sentence']])\n",
    "\n",
    "# Log breakdown per category\n",
    "logger.info(\n",
    "    \"Removal breakdown – empty: %d, only dots: %d, only colons: %d\",\n",
    "    mask_empty.sum(),\n",
    "    mask_dots.sum(),\n",
    "    mask_colons.sum()\n",
    ")\n",
    "\n",
    "# %% \n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def clean_punctuation(s: str) -> str:\n",
    "    # 1. Unicode-normaliseren zodat accenten gesplitst worden\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    # 2. alles wat geen letter, cijfer of spatie is, weghalen\n",
    "    s = re.sub(r\"[^\\w\\s]\", \"\", s)\n",
    "    # 3. meerdere spaties terugbrengen tot één\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    # 4. naar lowercase\n",
    "    return s.lower()\n",
    "\n",
    "df = df[~mask_removed].copy()\n",
    "df['sentence'] = (\n",
    "    df['sentence']\n",
    "      .str.strip()\n",
    "      .str.replace(r'\\.+', '', regex=True)\n",
    "      .str.replace(r'\"',   '', regex=True)\n",
    "      .apply(clean_punctuation)    # ← nieuwe stap\n",
    ")\n",
    "logger.info(f\"{len(df)} rows remain after cleaning\")\n",
    "\n",
    "# 4.  Prepare spaCy & adjective sets\n",
    "logger.info(\"Loading spaCy model\")\n",
    "nlp = spacy.load(\"nl_core_news_sm\", disable=[\"ner\",\"parser\"])\n",
    "\n",
    "male_adjs = {\n",
    "    \"corrupt\", \"onoverwinnelijk\", \"plaatsvervangend\", \"impopulair\", \"goddeloos\",\n",
    "    \"incompetent\", \"misdadig\", \"bekwaam\", \"sadistisch\", \"gewetenloos\",\n",
    "    \"steenrijk\", \"vooraanstaand\", \"voortvluchtig\", \"geniaal\", \"planmatig\", \"bekwaamheid\",\"genialiteit\"\n",
    "}\n",
    "female_adjs = {\n",
    "    \"blond\", \"beeldschoon\", \"bloedmooie\", \"donkerharig\", \"ongehuwd\",\n",
    "    \"kinderloos\", \"glamoureus\", \"beeldig\", \"sensueel\", \"platinablond\",\n",
    "    \"voorlijk\", \"feministisch\", \"stijlvol\", \"tuttig\", \"rimpelig\"\n",
    "}\n",
    "\n",
    "SUFFIXES     = (\"heid\", \"iteit\", \"eerder\", \"er\", \"st\")\n",
    "\n",
    "# %% \n",
    "# 5.  Core counting function — match on lemma ongeacht POS\n",
    "def count_adjs(text: str):\n",
    "    \"\"\"\n",
    "    Returns: male_count, female_count, male_hits, female_hits\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    male_hits = []\n",
    "    female_hits = []\n",
    "\n",
    "    for tok in doc:\n",
    "        lemma = tok.lemma_.lower()\n",
    "\n",
    "        # 1) Exact lemma match in male/female lijsten\n",
    "        if lemma in male_adjs:\n",
    "            male_hits.append(lemma)\n",
    "        elif lemma in female_adjs:\n",
    "            female_hits.append(lemma)\n",
    "        else:\n",
    "            # 2) Fuzzy fallback op lemma\n",
    "            best_male = max(male_adjs,   key=lambda a: fuzz.ratio(lemma, a))\n",
    "            best_fem  = max(female_adjs, key=lambda a: fuzz.ratio(lemma, a))\n",
    "            score_m   = fuzz.ratio(lemma, best_male)\n",
    "            score_f   = fuzz.ratio(lemma, best_fem)\n",
    "\n",
    "            if score_m >= FUZZY_THRESH and score_m >= score_f:\n",
    "                male_hits.append(best_male)\n",
    "            elif score_f >= FUZZY_THRESH:\n",
    "                female_hits.append(best_fem)\n",
    "\n",
    "    # per zin dedupliceren\n",
    "    return len(set(male_hits)), len(set(female_hits)), male_hits, female_hits\n",
    "\n",
    "\n",
    "# %% \n",
    "# 6.  Apply to DataFrame & log spaCy results\n",
    "logger.info(\"Beginning sentence-level adjective counting\")\n",
    "results = df[\"sentence\"].apply(count_adjs)\n",
    "df[[\"male_count\",\"female_count\",\"male_matches\",\"female_matches\"]] = \\\n",
    "    pd.DataFrame(results.tolist(), index=df.index)\n",
    "df[\"total_in_lists\"] = df[\"male_count\"] + df[\"female_count\"]\n",
    "\n",
    "# Overall stats\n",
    "total_sentences = len(df)\n",
    "total_male_adjs = df[\"male_count\"].sum()\n",
    "total_female_adjs = df[\"female_count\"].sum()\n",
    "logger.info(\n",
    "    \"Processed %d sentences: total male adjectives=%d, total female adjectives=%d\",\n",
    "    total_sentences, total_male_adjs, total_female_adjs\n",
    ")\n",
    "\n",
    "# Top 5 adjectives by frequency\n",
    "male_flat   = Counter(adj for lst in df[\"male_matches\"]   for adj in lst)\n",
    "female_flat = Counter(adj for lst in df[\"female_matches\"] for adj in lst)\n",
    "\n",
    "# %% \n",
    "# 7.  Save cleaned & counted data\n",
    "CSV_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(CSV_OUT, index=False, encoding=ENCODING)\n",
    "logger.info(f\"Saved cleaned & counted data to {CSV_OUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# define path for the no‑hit file\n",
    "CSV_NO_HITS = Path(\"output/sentences_no_hits.csv\")\n",
    "\n",
    "# ensure output directory exists\n",
    "CSV_NO_HITS.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# filter again just to be safe\n",
    "no_hits_df = df[df[\"total_in_lists\"] == 0]\n",
    "\n",
    "# log how many and save only the 'sentence' column (or whole row if you prefer)\n",
    "logger.info(f\"Saving {len(no_hits_df)} sentences with no adjective hits to {CSV_NO_HITS}\")\n",
    "no_hits_df[[\"sentence\"]].to_csv(CSV_NO_HITS, index=False, encoding=ENCODING)\n",
    "\n",
    "CSV_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(CSV_OUT, index=False, encoding=ENCODING)\n",
    "logger.info(f\"Saved cleaned & counted data to {CSV_OUT}\")\n",
    "\n",
    "logger.info(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "# 9.  Summary by noun_gender × adjective_gender (with percentages)\n",
    "total_sentences = len(df)\n",
    "\n",
    "summary = (\n",
    "    df\n",
    "    .groupby(['noun_gender', 'adjective_gender'])\n",
    "    .size()\n",
    "    .reset_index(name='sentence_count')\n",
    "    .assign(\n",
    "        percentage=lambda d: (d['sentence_count'] / total_sentences) * 100\n",
    "    )\n",
    "    .sort_values('sentence_count', ascending=False)\n",
    ")\n",
    "\n",
    "# Display in notebook\n",
    "print(\"Sentence counts by noun_gender and adjective_gender (with % of total):\")\n",
    "print(summary)\n",
    "\n",
    "# Save summary to CSV\n",
    "summary_path = CSV_OUT.parent / \"summary_by_gender.csv\"\n",
    "summary.to_csv(summary_path, index=False, encoding=ENCODING)\n",
    "logger.info(f\"Saved summary breakdown (with percentages) to {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"output/sentences_cleaned.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# Summary by model × noun_gender × adjective_gender × temperature\n",
    "summary = (\n",
    "    df\n",
    "    .groupby(['model', 'temperature', 'noun_gender', 'adjective_gender'])\n",
    "    .size()\n",
    "    .reset_index(name='sentence_count')\n",
    ")\n",
    "\n",
    "# Compute percentage within each model-temperature group\n",
    "summary['percentage'] = (\n",
    "    summary\n",
    "    .groupby(['model', 'temperature'])['sentence_count']\n",
    "    .transform(lambda x: x / x.sum() * 100)\n",
    ")\n",
    "\n",
    "# Sort for readability\n",
    "summary = summary.sort_values(['model', 'temperature', 'sentence_count'], ascending=[True, True, False])\n",
    "\n",
    "# Display the summary\n",
    "print(\"Sentence counts by model, temperature, noun_gender & adjective_gender\", summary)\n",
    "\n",
    "# Save to CSV\n",
    "summary.to_csv(\"output/summary_by_model_temp_gender.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure sentence_count is integer for formatting\n",
    "summary[\"sentence_count\"] = summary[\"sentence_count\"].round().astype(int)\n",
    "\n",
    "# Create a compact label for gender pair\n",
    "summary[\"gender_pair\"] = summary[\"noun_gender\"].str[0] + \"/\" + summary[\"adjective_gender\"].str[0]\n",
    "models = summary[\"model\"].unique()\n",
    "n_models = len(models)\n",
    "\n",
    "# Seaborn aesthetics\n",
    "sns.set(style=\"white\", font_scale=1.2)\n",
    "\n",
    "# Figure & shared colorbar\n",
    "fig, axes = plt.subplots(1, n_models, figsize=(5.5 * n_models, 5), sharey=True)\n",
    "vmin = summary[\"sentence_count\"].min()\n",
    "vmin = int(vmin)\n",
    "vmax = summary[\"sentence_count\"].max()\n",
    "vmax = int(vmax)\n",
    "cbar_ax = fig.add_axes([0.93, 0.15, 0.02, 0.7])  # Colorbar at right\n",
    "\n",
    "# Create one subplot per model\n",
    "for i, (ax, model) in enumerate(zip(axes, models)):\n",
    "    df_model = summary[summary[\"model\"] == model]\n",
    "    heatmap_data = df_model.pivot(index=\"gender_pair\", columns=\"temperature\", values=\"sentence_count\")\n",
    "\n",
    "    sns.heatmap(\n",
    "        heatmap_data,\n",
    "        annot=True,\n",
    "        fmt=\"d\",  # Now safe to use integer formatting\n",
    "        cmap=\"YlGnBu\",\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"white\",\n",
    "        cbar=i == n_models - 1,\n",
    "        cbar_ax=cbar_ax if i == n_models - 1 else None,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        square=True,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ax.set_title(model, fontsize=13)\n",
    "    ax.set_xlabel(\"Temperature\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Noun / Adjective Gender\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "# Add main title and adjust layout\n",
    "plt.suptitle(\"Valid Sentence Count by Gender Pair and Temperature\", fontsize=15, y=1.03)\n",
    "plt.tight_layout(rect=[0, 0, 0.92, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "# 10.  Summary by model × noun_gender × adjective_gender (with per-model %)\n",
    "# (no need to re-read the CSV if you still have `df` in memory)\n",
    "\n",
    "summary = (\n",
    "    df\n",
    "    .groupby(['model', 'noun_gender', 'adjective_gender'])\n",
    "    .size()\n",
    "    .reset_index(name='sentence_count')\n",
    ")\n",
    "\n",
    "# Compute percentage within each model\n",
    "summary['percentage'] = (\n",
    "    summary\n",
    "    .groupby('model')['sentence_count']\n",
    "    .transform(lambda x: x / x.sum() * 100)\n",
    ")\n",
    "\n",
    "# Sort for readability\n",
    "summary = summary.sort_values(['model', 'sentence_count'], ascending=[True, False])\n",
    "\n",
    "# Display the summary\n",
    "print(\"Sentence counts by model, noun_gender & adjective_gender (out of {:,} sentences)\\n\".format(len(df)))\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "# Save to disk\n",
    "summary.to_csv(\"output/summary_by_model_gender.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"\\nSaved summary to output/summary_by_model_gender.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your cleaned dataset (adjust path if needed)\n",
    "df = pd.read_csv(\"output/sentences_cleaned.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# a) Total number of rows per word\n",
    "word_counts = (\n",
    "    df['word']\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    "    .rename(columns={'index': 'word', 'word': 'occurrence_count'})\n",
    ")\n",
    "\n",
    "# d) Inspect the first few rows\n",
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 7.  Leakage summary\n",
    "# ---------------------------------------------------------------------\n",
    "pct_multi = (df['total_in_lists'] > 1).mean() * 100\n",
    "# ---------------------------------------------------------------------\n",
    "# 8.  Print example sentences with both male & female adjectives\n",
    "# ---------------------------------------------------------------------\n",
    "# Print to console (and log)\n",
    "print(f\"% sentences with more than one adjective: {pct_multi:.2f}%\")\n",
    "logger.info(\"Leakage summary — >1 count: %.2f%%;\",\n",
    "            pct_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate leakage by model × temperature\n",
    "agg_model_temp = (\n",
    "    df\n",
    "    .groupby(['model', 'temperature'])\n",
    "    .apply(lambda sub: (sub['total_in_lists'] > 1).mean() * 100)\n",
    "    .reset_index(name='pct_multi')\n",
    ")\n",
    "\n",
    "# Plot each model in its own color\n",
    "plt.figure()\n",
    "for model in agg_model_temp['model'].unique():\n",
    "    subset = agg_model_temp[agg_model_temp['model'] == model]\n",
    "    plt.plot(\n",
    "        subset['temperature'],\n",
    "        subset['pct_multi'],\n",
    "        marker='o',\n",
    "        label=model\n",
    "    )\n",
    "\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Leakage (%)')\n",
    "plt.title('Leakage vs. Temperature by Model')\n",
    "plt.legend(title=\"Model\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ——— 1. derive prompt_type ———\n",
    "# Map “male”→“M”, “female”→“F” and build e.g. “M→F”, “F→M”, etc.\n",
    "gender_map = {\"male\":\"M\", \"female\":\"F\"}\n",
    "df[\"prompt_type\"] = (\n",
    "    df[\"adjective_gender\"].map(gender_map)\n",
    "  + \"→\"\n",
    "  + df[\"noun_gender\"].map(gender_map)\n",
    ")\n",
    "\n",
    "# ——— 3. Prompt‑structure interaction ———\n",
    "pt = (\n",
    "    df\n",
    "    .groupby(\"prompt_type\")\n",
    "    .apply(lambda sub: pd.Series({\n",
    "        \"pct_multi\": (sub[\"total_in_lists\"]>1).mean()*100,\n",
    "    \n",
    "    }))\n",
    "    .round(2)\n",
    ")\n",
    "print(\"\\nLeakage by prompt structure:\\n\", pt)\n",
    "\n",
    "import numpy as np\n",
    "# grouped bar chart\n",
    "labels = pt.index.tolist()\n",
    "x = np.arange(len(labels))\n",
    "plt.bar(x-0.15, pt[\"pct_multi\"], width=0.3, label=\"Multi‑adj\")\n",
    "plt.xticks(x, labels); plt.ylabel(\"Leakage (%)\")\n",
    "plt.title(\"Leakage by Prompt Structure\")\n",
    "plt.legend(); plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leakage by prompt_type\n",
    "pt = df.groupby('prompt_type').apply(lambda sub: pd.Series({\n",
    "    'pct_multi': (sub['total_in_lists']>1).mean()*100,\n",
    "    'pct_co':    ((sub['male_count']>0)&(sub['female_count']>0)).mean()*100\n",
    "})).round(2)\n",
    "\n",
    "print(pt)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "labels = pt.index.tolist()\n",
    "multi = pt['pct_multi'].values\n",
    "co    = pt['pct_co'].values\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(x-0.15, multi, width=0.3, label='Multi‑adj')\n",
    "plt.bar(x+0.15, co,    width=0.3, label='Co‑occur')\n",
    "plt.xticks(x, labels)\n",
    "plt.ylabel('Leakage (%)')\n",
    "plt.title('Leakage by Prompt Structure')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Count each category\n",
    "count_MM = len(df[(df['noun_gender']=='male') & (df['adjective_gender']=='male')])\n",
    "count_FF = len(df[(df['noun_gender']=='female') & (df['adjective_gender']=='female')])\n",
    "count_MF = len(df[(df['noun_gender']=='male') & (df['adjective_gender']=='female')])\n",
    "count_FM = len(df[(df['noun_gender']=='female') & (df['adjective_gender']=='male')])\n",
    "\n",
    "# 2. Totals\n",
    "total_S = count_MM + count_FF\n",
    "total_C = count_MF + count_FM\n",
    "grand_total = len(df)\n",
    "\n",
    "# 3. Percentages (relative to each half of the dataset)\n",
    "pct_MM = count_MM / total_S * 100\n",
    "pct_FF = count_FF / total_S * 100\n",
    "pct_MF = count_MF / total_C * 100\n",
    "pct_FM = count_FM / total_C * 100\n",
    "\n",
    "# 4. Build summary table\n",
    "summary = pd.DataFrame({\n",
    "    '': [\n",
    "        'Consistent with gender stereotype (S)',\n",
    "        'Contradictory to gender stereotype (S)',\n",
    "        'Total'\n",
    "    ],\n",
    "    '#MM': [f\"{count_MM} ({pct_MM:.1f}%)\", f\"{count_MF} ({pct_MF:.1f}%)\", ''],\n",
    "    '#FF': [f\"{count_FF} ({pct_FF:.1f}%)\", f\"{count_FM} ({pct_FM:.1f}%)\", ''],\n",
    "    '#Total': [f\"{total_S} ({total_S/grand_total*100:.1f}%)\",\n",
    "               f\"{total_C} ({total_C/grand_total*100:.1f}%)\",\n",
    "               f\"{grand_total}\"]\n",
    "})\n",
    "\n",
    "# 5. Display the table\n",
    "print(\"Table 2: Labeling details with size & distribution\", summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
