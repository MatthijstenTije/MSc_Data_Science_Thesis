# Dutch Adjective Gender Bias Detection

A Thesis Project for the MSc in Data Science & Society â€“ Tilburg University

This repository supports the thesis titled:
__â€œInvestigating Gender Bias in Large Language Models Through Dutch Text Generation: Assessing the Role of Embeddings, Pretraining, and Alignmentâ€__,  submitted in partial fulfillment of the requirements for the Master of Science in Data Science & Society at Tilburg University, School of Humanities and Digital Sciences.

---

## Table of Contents

- [Dutch Adjective Gender Bias Detection](#dutch-adjective-gender-bias-detection)
  - [Table of Contents](#table-of-contents)
  - [Overview](#overview)
  - [Project Structure](#project-structure)
  - [Installation and Requirements](#installation-and-requirements)
  - [ğŸ“¥ How to Download and Run LLaMA Models (Local)](#-how-to-download-and-run-llama-models-local)
    - [Step-by-Step Instructions:](#step-by-step-instructions)
  - [Data Sources](#data-sources)
  - [Analysis Workflow](#analysis-workflow)
  - [ğŸ§¾ Source, Ethics, Code, and Technology Statement](#-source-ethics-code-and-technology-statement)
    - [ğŸ“š Data Source](#-data-source)
    - [âš–ï¸ Ethics Statement](#ï¸-ethics-statement)

---

## Overview

This research investigates **gender bias in Dutch Large Language Models (LLMs)** by analyzing how gendered connotations are embedded in and reproduced by language models.

Building on English-language findings, this study asks whether similar biases arise in Dutchâ€”a language without grammatical gender marking in adjectives.

The analysis unfolds in three main phases:

1. **Embedding Analysis**  
   - Identify gender-coded Dutch adjectives using FastText and Word2Vec embeddings  
   - Apply cosine similarity and RIPA metrics to detect and quantify bias  

2. **Controlled Sentence Generation**  
   - Generate 16,000 Dutch sentences using four LLaMA-based models (via Ollama)  
   - Vary alignment (e.g., RLHF, QA tuning) and sampling temperature  

3. **Classifier Evaluation**  
   - Use RobBERT, BERTje, and DistilBERT to assess stereotype consistency  
   - Quantify downstream bias via True Positive Rate (TPR) gaps  

Bias patterns are statistically tested and visualized, demonstrating that gender associations in embeddings persist and propagate through generation and classification pipelines.

---

## Project Structure

```
â”œâ”€â”€ data
â”œâ”€â”€ phase_01
â”‚   â”œâ”€â”€ output
â”‚   â”œâ”€â”€ bias_metrics.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ ripa_analysis.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ visualization.py
â”œâ”€â”€ phase_02
â”‚   â”œâ”€â”€ logs
â”‚   â”‚   â”œâ”€â”€ llama2-uncensored
â”‚   â”‚   â”œâ”€â”€ llama3_8b
â”‚   â”‚   â””â”€â”€ llama3_text
â”‚   â”œâ”€â”€ llama3-chatqa_8b
â”‚   â”‚   â”œâ”€â”€ main.log
â”‚   â”‚   â””â”€â”€ quality_issues.json
â”‚   â”œâ”€â”€ output
â”‚   â”‚   â””â”€â”€ intermediate
â”‚   â”‚       â””â”€â”€ llama3-chatqa_8b_female_female_temp1_5_state_1745780595.json
â”‚   â”œâ”€â”€ prompts
â”‚   â”‚   â”œâ”€â”€ prompt_femaleNouns_femaleAdjs.txt
â”‚   â”‚   â”œâ”€â”€ prompt_femaleNouns_maleAdjs.txt
â”‚   â”‚   â”œâ”€â”€ prompt_maleNouns_femaleAdjs.txt
â”‚   â”‚   â””â”€â”€ prompt_maleNouns_maleAdjs.txt
â”‚   â”œâ”€â”€ visualizations
â”‚   â”œâ”€â”€ 01_async_generate_sentences.py
â”‚   â”œâ”€â”€ 02_convert_logs_to_csv.py
â”‚   â”œâ”€â”€ 03_clean_sentences.py
â”‚   â”œâ”€â”€ 04_gender_summary.py
â”‚   â”œâ”€â”€ 05_temp_gender_summary.py
â”‚   â”œâ”€â”€ 06_model_gender_summary.py
â”‚   â”œâ”€â”€ 07_word_counts.py
â”‚   â”œâ”€â”€ 08_iterations_visualization.py
â”‚   â”œâ”€â”€ 09_error_analysis.py
â”‚   â”œâ”€â”€ 10_leakage.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ old_generate_sentences.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ phase_03
â”‚   â”œâ”€â”€ visualizations
â”‚   â”‚   â”œâ”€â”€ Classifier_BERT.ipynb
â”‚   â”‚   â”œâ”€â”€ Classifier_DistillBERT.ipynb
â”‚   â”‚   â”œâ”€â”€ Classifier_RobBERT.ipynb
â”‚   â”‚   â”œâ”€â”€ fold_visualization.py
â”‚   â”‚   â”œâ”€â”€ make_accuracy_summary.py
â”‚   â”‚   â”œâ”€â”€ make_borda_ranking.py
â”‚   â”‚   â”œâ”€â”€ make_trp_gap_summary.py
â”‚   â”‚   â”œâ”€â”€ visualization_accuracy.py
â”‚   â”‚   â””â”€â”€ visualization_tpr_gap.py
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

```

---

## Installation and Requirements

**Python Version**: 3.7 or later is recommended.

Install all required dependencies:

```bash
pip install -r requirements.txt
python -m spacy download nl_core_news_lg
```

---

## ğŸ“¥ How to Download and Run LLaMA Models (Local)

For reproducible generation of Dutch text, this project uses four variants of Metaâ€™s LLaMA models, executed locally via [Ollama](https://ollama.com):

### Step-by-Step Instructions:

1. **Install Ollama** (macOS, Linux, or Windows):
   ```bash
   curl -fsSL https://ollama.com/install.sh | sh
   ```

2. **Run LLaMA model variants**:
   ```bash
   ollama run llama3
   ollama run llama3:chat
   ollama run llama3:text
   ollama run llama2-uncensored
   ```

3. **Configuration**:
   - Use fixed seeds and temperatures in prompt scripts for consistency.
   - Prompts are in `phase_02/prompts/`.

âš ï¸ **Note**: These models may generate biased content. Dataset is not shared publicly but available on academic request.

---


## Data Sources

- **Dutch FastText Embeddings**: Download from [FastText Crawl Vectors](https://fasttext.cc/docs/en/crawl-vectors.html).
- **Word2Vec Sonar Embeddings**: (Provide download link if available).
- **Dutch Corpus CSV**: `Corpus_Hedendaags_Nederlands_Adjectives.csv`, parsed to extract adjectives.

Make sure to update file paths in your scripts and notebooks to match your local environment.

---

## Analysis Workflow

1. Load the Dutch embeddings (FastText and Sonar Word2Vec).
2. Parse the Dutch corpus and extract adjectives.
3. Filter adjectives and ensure they exist in the embedding vocabulary.
4. Compute gender bias scores:
   - Cosine similarity between adjectives and male/female word sets.
   - Statistical significance via permutation tests.
   - RIPA bias analysis using WEFE.
5. Visualize results with scatter plots, bar charts, and bias distributions.

Run the full analysis:

```bash
python main.py
```

---

## ğŸ§¾ Source, Ethics, Code, and Technology Statement

### ğŸ“š Data Source

- **GiGaNT corpus** from [Institute for the Dutch Language](https://ivdnt.org/corpora-lexica/gigant/)
- **CHN corpus** via [CLARIN portal](https://portal.clarin.ivdnt.org/corpus-frontend-chn/chn-extern/search/)
- **Embeddings**:
  - [FastText cc.nl.300.vec.gz](https://fasttext.cc/docs/en/crawl-vectors.html)
  - [Word2Vec (SoNaR)](https://github.com/clips/dutchembeddings)
- **Sentence generation**:
  - 16,000 sentences generated using LLaMA models locally via Ollama
- **Transformers for bias detection**:
  - [DistilBERT](https://huggingface.co/distilbert-base-multilingual-cased)
  - [BERTje](https://huggingface.co/GroNLP/bert-base-dutch-cased)
  - [RobBERT 2023](https://huggingface.co/DTAI-KULeuven/robbert-2023-dutch-large)
  - Executed on Runpod.io using NVIDIA A5000 GPUs

All figures and outputs were generated by the author.

---

### âš–ï¸ Ethics Statement

This project includes generated sentences reflecting gender stereotypes for research purposes. While this helps identify and quantify bias, it may also unintentionally replicate harmful representations.

To mitigate risk:
- Dataset is **restricted** and only available for academic purposes upon request.
- Generation was **controlled and reproducible**.
- Use of these materials for reinforcement or deployment without context is **explicitly discouraged**.

---
